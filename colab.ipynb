{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9XxJrdrfQbI"
      },
      "source": [
        "### <font size=5px color=\"#95C7AE\">防止Google Colab自動中斷程式碼:</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvMvNl8WeFpY"
      },
      "source": [
        "<p><font size=3px > 每60分鐘自動執行程式碼刷新，解除90分鐘斷開限制.\n",
        "<p><font size=3px > 使用方法：colab頁面按下F12或Ctrl+Shift+I (mac按Option+Command+I) 在console（控制台） 輸入以下程式碼並回車. </p>< b>複製以下程式碼貼在瀏覽器console！ ！ 請勿關閉瀏覽器以免失效</b>\n",
        "\n",
        "\n",
        "```javascript\n",
        "function ConnectButton(){\n",
        "     console.log(\"Connect pushed\");\n",
        "     document.querySelector(\"#connect\").click()\n",
        "}\n",
        "setInterval(ConnectButton,60000);\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5R5MoAGd0pL",
        "outputId": "a825300f-1c5b-4f46-c575-51de42c8d4d3"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              " function ClickConnect(){\n",
              "   btn = document.querySelector(\"colab-connect-button\")\n",
              "   if (btn != null){\n",
              "…\n",
              "setInterval(ClickConnect,60000)\n"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done.\n"
          ]
        }
      ],
      "source": [
        "#@markdown <h3>← 輸入了程式碼後運行以防止斷開</h>\n",
        "\n",
        "\n",
        "import IPython\n",
        "from google.colab import output\n",
        "\n",
        "display(IPython.display.Javascript('''\n",
        " function ClickConnect(){\n",
        "   btn = document.querySelector(\"colab-connect-button\")\n",
        "   if (btn != null){\n",
        "…\n",
        "setInterval(ClickConnect,60000)\n",
        "'''))\n",
        "\n",
        "print(\"Done.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4S4x35Cce8JU"
      },
      "source": [
        "### <font size=3px color=\"#95C7AE\"> main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KLSgrIteJbg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cbaed33-6c69-4ea2-a1d9-dd1b123bd77a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.sys.path.append('..')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-multilearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcZmjOF4lClf",
        "outputId": "157488a6-658a-4478-9fe2-5d57daa7eddf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-multilearn\n",
            "  Downloading scikit_multilearn-0.2.0-py3-none-any.whl (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.4/89.4 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-multilearn\n",
            "Successfully installed scikit-multilearn-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/mid/\n",
        "from skmultilearn.model_selection import IterativeStratification\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D,Dropout, BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import backend as K\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "\n",
        "\n",
        "folders = os.listdir('processed_data_all')\n",
        "\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "for folder in tqdm(folders,desc='load image'):\n",
        "    if not os.path.isdir(f'processed_data_all/{folder}'):\n",
        "        continue\n",
        "    for file in os.listdir(f'processed_data_all/{folder}'):\n",
        "        image = cv2.imread(f'processed_data_all/{folder}/{file}')\n",
        "        processed_image = image\n",
        "        data.append(processed_image)\n",
        "        labels.append(folder)\n",
        "\n",
        "\n",
        "# Assume image_list is your list of images and label_list is your list of labels\n",
        "# Convert the list of images to a NumPy array\n",
        "X = np.array(data)/255.0\n",
        "\n",
        "# Convert the list of labels to a NumPy array\n",
        "labels = [list(map(int, label)) for label in labels]\n",
        "y = np.array(labels)\n",
        "\n",
        "\n",
        "# Assume X is your feature matrix and y is your multi-label target matrix\n",
        "k_fold = IterativeStratification(n_splits=5, order=1)\n",
        "\n",
        "def partial_correct_accuracy(y_true, y_pred):\n",
        "    y_true = tf.cast(y_true, 'bool')\n",
        "    y_pred = tf.cast(tf.round(y_pred), 'bool')\n",
        "    p = tf.reduce_sum(tf.cast(tf.logical_and(y_true, y_pred), 'float32'), axis=-1)\n",
        "    q = tf.reduce_sum(tf.cast(tf.logical_or(y_true, y_pred), 'float32'), axis=-1)\n",
        "    return tf.reduce_mean(tf.where(tf.equal(q, 0), 0.0, p / q))\n",
        "\n",
        "def history_plot(train_history, i):\n",
        "    # 繪製訓練和驗證的準確度、損失值和partial_correct_accuracy\n",
        "    plt.figure(figsize=(18, 4))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.plot(train_history.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(train_history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title(f'Fold {i+1} Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.plot(train_history.history['loss'], label='Train Loss')\n",
        "    plt.plot(train_history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title(f'Fold {i+1} Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.plot(train_history.history['partial_correct_accuracy'], label='Train Partial Correct Accuracy')\n",
        "    plt.plot(train_history.history['val_partial_correct_accuracy'], label='Validation Partial Correct Accuracy')\n",
        "    plt.title(f'Fold {i+1} Partial Correct Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Partial Correct Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.savefig(f'/content/fold_{i+1}_history.png')\n",
        "    plt.close()\n",
        "\n",
        "# 創建一個ImageDataGenerator對象來進行資料擴增\n",
        "datagen = ImageDataGenerator(\n",
        "    # width_shift_range=0.1,\n",
        "    # height_shift_range=0.1,\n",
        "    # rotation_range=30,\n",
        "    # fill_mode='nearest',\n",
        "    horizontal_flip=True,\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# 在迴圈外部初始化一個列表來保存每次迭代的評估分數\n",
        "scores = []\n",
        "history_list = []\n",
        "for i, (train_index, test_index) in enumerate(k_fold.split(X, y)):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64, 48, 3)))\n",
        "    #model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Dropout(0.6))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    #model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(5, activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizer='rmsprop',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy', partial_correct_accuracy])\n",
        "\n",
        "\n",
        "\n",
        "    # 使用ImageDataGenerator對象來擴增訓練數據\n",
        "    train_gen = datagen.flow(X_train, y_train, batch_size=32)\n",
        "\n",
        "    # 從訓練數據生成器中獲取一批數據\n",
        "    data_batch, labels_batch = next(train_gen)\n",
        "\n",
        "    # 繪製第一個圖片\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow((data_batch[0]*255).astype('int'))\n",
        "    plt.title('Augmented Image')\n",
        "    # 儲存圖片\n",
        "    plt.savefig('/content/augmented_image.png')\n",
        "    plt.close()\n",
        "\n",
        "    train_history = model.fit(\n",
        "        X_train,\n",
        "        y_train,\n",
        "        epochs=80,\n",
        "        validation_data=(X_test, y_test),\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "     # 在每次迭代結束後，評估模型並保存評估分數和訓練歷程\n",
        "    score = model.evaluate(X_test, y_test)\n",
        "    scores.append(score)\n",
        "    history_list.append(train_history)\n",
        "\n",
        "    history_plot(train_history, i)\n",
        "\n",
        "# 計算平均分數\n",
        "average_score = np.mean(scores, axis=0)\n",
        "print(f'Average loss: {average_score[0]}')\n",
        "print(f'Average accuracy: {average_score[1]}')\n",
        "print(f'Average partial correct accuracy: {average_score[2]}')\n"
      ],
      "metadata": {
        "id": "pColxrcjkHqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/mid/\n",
        "from skmultilearn.model_selection import IterativeStratification\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D,Dropout, BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import backend as K\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "\n",
        "\n",
        "folders = os.listdir('processed_data_all')\n",
        "\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "for folder in tqdm(folders,desc='load image'):\n",
        "    if not os.path.isdir(f'processed_data_all/{folder}'):\n",
        "        continue\n",
        "    for file in os.listdir(f'processed_data_all/{folder}'):\n",
        "        image = cv2.imread(f'processed_data_all/{folder}/{file}')\n",
        "        processed_image = image\n",
        "        data.append(processed_image)\n",
        "        labels.append(folder)\n",
        "\n",
        "\n",
        "# Assume image_list is your list of images and label_list is your list of labels\n",
        "# Convert the list of images to a NumPy array\n",
        "X = np.array(data)/255.0\n",
        "\n",
        "# Convert the list of labels to a NumPy array\n",
        "labels = [list(map(int, label)) for label in labels]\n",
        "y = np.array(labels)\n",
        "\n",
        "\n",
        "# Assume X is your feature matrix and y is your multi-label target matrix\n",
        "k_fold = IterativeStratification(n_splits=5, order=1)\n",
        "\n",
        "def partial_correct_accuracy(y_true, y_pred):\n",
        "    y_true = tf.cast(y_true, 'bool')\n",
        "    y_pred = tf.cast(tf.round(y_pred), 'bool')\n",
        "    p = tf.reduce_sum(tf.cast(tf.logical_and(y_true, y_pred), 'float32'), axis=-1)\n",
        "    q = tf.reduce_sum(tf.cast(tf.logical_or(y_true, y_pred), 'float32'), axis=-1)\n",
        "    return tf.reduce_mean(tf.where(tf.equal(q, 0), 0.0, p / q))\n",
        "\n",
        "def history_plot(train_history, i):\n",
        "    # 繪製訓練和驗證的準確度、損失值和partial_correct_accuracy\n",
        "    plt.figure(figsize=(18, 4))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.plot(train_history.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(train_history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title(f'Fold {i+1} Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.plot(train_history.history['loss'], label='Train Loss')\n",
        "    plt.plot(train_history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title(f'Fold {i+1} Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.plot(train_history.history['partial_correct_accuracy'], label='Train Partial Correct Accuracy')\n",
        "    plt.plot(train_history.history['val_partial_correct_accuracy'], label='Validation Partial Correct Accuracy')\n",
        "    plt.title(f'Fold {i+1} Partial Correct Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Partial Correct Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.savefig(f'/content/fold_{i+1}_history.png')\n",
        "    plt.close()\n",
        "\n",
        "# 創建一個ImageDataGenerator對象來進行資料擴增\n",
        "datagen = ImageDataGenerator(\n",
        "    # width_shift_range=0.1,\n",
        "    # height_shift_range=0.1,\n",
        "    # rotation_range=30,\n",
        "    # fill_mode='nearest',\n",
        "    horizontal_flip=True,\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# 在迴圈外部初始化一個列表來保存每次迭代的評估分數\n",
        "scores = []\n",
        "history_list = []\n",
        "for i, (train_index, test_index) in enumerate(k_fold.split(X, y)):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64, 48, 3)))\n",
        "    #model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Dropout(0.6))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    #model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(5, activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizer='rmsprop',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy', partial_correct_accuracy])\n",
        "\n",
        "\n",
        "\n",
        "    # 使用ImageDataGenerator對象來擴增訓練數據\n",
        "    train_gen = datagen.flow(X_train, y_train, batch_size=32)\n",
        "\n",
        "    # 從訓練數據生成器中獲取一批數據\n",
        "    data_batch, labels_batch = next(train_gen)\n",
        "\n",
        "    # 繪製第一個圖片\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow((data_batch[0]*255).astype('int'))\n",
        "    plt.title('Augmented Image')\n",
        "    # 儲存圖片\n",
        "    plt.savefig('/content/augmented_image.png')\n",
        "    plt.close()\n",
        "\n",
        "    model.summary()\n",
        "    plot_model(model, to_file='/content/model.png', show_shapes=True)\n",
        "\n",
        "    train_history = model.fit(\n",
        "        X_train,\n",
        "        y_train,\n",
        "        epochs=80,\n",
        "        validation_data=(X_test, y_test),\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "     # 在每次迭代結束後，評估模型並保存評估分數和訓練歷程\n",
        "    score = model.evaluate(X_test, y_test)\n",
        "    scores.append(score)\n",
        "    history_list.append(train_history)\n",
        "\n",
        "    history_plot(train_history, i)\n",
        "\n",
        "# 計算平均分數\n",
        "average_score = np.mean(scores, axis=0)\n",
        "print(f'Average loss: {average_score[0]}')\n",
        "print(f'Average accuracy: {average_score[1]}')\n",
        "print(f'Average partial correct accuracy: {average_score[2]}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3k9pzXRTzH9W",
        "outputId": "ebc98e2b-1ce9-4c2e-a9d5-ebef36153fca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/mid\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "load image: 100%|██████████| 32/32 [00:03<00:00,  8.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_16 (Conv2D)          (None, 62, 46, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_16 (MaxPooli  (None, 31, 23, 32)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_24 (Dropout)        (None, 31, 23, 32)        0         \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 29, 21, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_16 (Ba  (None, 29, 21, 64)        256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_17 (MaxPooli  (None, 14, 10, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_25 (Dropout)        (None, 14, 10, 64)        0         \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (None, 8960)              0         \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 64)                573504    \n",
            "                                                                 \n",
            " dropout_26 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            " batch_normalization_17 (Ba  (None, 64)                256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 597893 (2.28 MB)\n",
            "Trainable params: 597637 (2.28 MB)\n",
            "Non-trainable params: 256 (1.00 KB)\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-f8e693f0f575>\u001b[0m in \u001b[0;36m<cell line: 99>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/model.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m     train_history = model.fit(\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/colab/hand_posture\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D,Dropout\n",
        "from keras import backend as K\n",
        "def pipeline_process(image):\n",
        "    image = resize(image, 64)\n",
        "    ''' image = clear_pixels_by_hue(image)\n",
        "    image = remove_noise(image) '''\n",
        "    return image\n",
        "# Step 1: 遍歷 raw_data 資料夾中的所有子資料夾\n",
        "folders = os.listdir('processed_data')\n",
        "\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "for folder in tqdm(folders,desc='load image'):\n",
        "    if not os.path.isdir(f'processed_data/{folder}'):\n",
        "        continue\n",
        "    for file in os.listdir(f'processed_data/{folder}'):\n",
        "        image = cv2.imread(f'processed_data/{folder}/{file}')\n",
        "        processed_image = pipeline_process(image)\n",
        "        data.append(processed_image)\n",
        "        labels.append(folder)\n",
        "        # 位移後的圖片\n",
        "        M = np.float32([[1, 0, 10], [0, 1, 5]])  # 位移矩陣\n",
        "        shifted_image = cv2.warpAffine(processed_image, M, (processed_image.shape[1], processed_image.shape[0]))\n",
        "        data.append(shifted_image)\n",
        "        labels.append(folder)\n",
        "        M = np.float32([[1, 0, -10], [0, 1, -5]])  # 位移矩陣\n",
        "        shifted_image2 = cv2.warpAffine(processed_image, M, (processed_image.shape[1], processed_image.shape[0]))\n",
        "        data.append(shifted_image2)\n",
        "        labels.append(folder)\n",
        "\n",
        "# Step 3: 將處理後的圖片和對應的標籤（子資料夾名稱）存入一個數據集中\n",
        "data = np.array(data)\n",
        "labels = np.array(labels)\n",
        "''' flipped_data = data[:, :, ::-1, :]\n",
        "combined_data = np.concatenate((data, flipped_data), axis=0)\n",
        "combined_labels = np.concatenate((labels, labels), axis=0) '''\n",
        "# 將標籤二值化\n",
        "lb = LabelBinarizer()\n",
        "labels = [[int(bit) for bit in label] for label in labels]\n",
        "# 將標籤二值化\n",
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(labels)\n",
        "print(labels)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwaeVmxwt_do",
        "outputId": "66dea292-a49e-460e-9842-eaf22d816479"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/11gva2C9vGefcaGXnVGvkqhvm-5FkuR7i/colab/hand_posture\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "load image: 100%|██████████| 32/32 [01:51<00:00,  3.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " ...\n",
            " [1 1 1 1 1]\n",
            " [1 1 1 1 1]\n",
            " [1 1 1 1 1]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def partial_correct_accuracy(y_true, y_pred):\n",
        "    y_true = tf.cast(y_true, 'bool')\n",
        "    y_pred = tf.cast(tf.round(y_pred), 'bool')\n",
        "    p = tf.reduce_sum(tf.cast(tf.logical_and(y_true, y_pred), 'float32'), axis=-1)\n",
        "    q = tf.reduce_sum(tf.cast(tf.logical_or(y_true, y_pred), 'float32'), axis=-1)\n",
        "    return tf.reduce_mean(tf.where(tf.equal(q, 0), 0.0, p / q))\n",
        "# Step 4: 使用這個數據集來訓練一個模型，進行手指預測\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64, 48, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(5, activation='sigmoid'))\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy', partial_correct_accuracy])\n",
        "\n",
        "train_history = model.fit(data, labels, epochs=10, validation_split = 0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5mM5AgJuUGC",
        "outputId": "40af0b68-cfdd-4f6a-ae2e-cd36722d4226"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "27/27 [==============================] - 2s 17ms/step - loss: 5.1906 - accuracy: 0.2799 - partial_correct_accuracy: 0.4200 - val_loss: 0.6554 - val_accuracy: 0.4583 - val_partial_correct_accuracy: 0.6375\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6529 - accuracy: 0.3217 - partial_correct_accuracy: 0.4978 - val_loss: 0.5517 - val_accuracy: 0.4896 - val_partial_correct_accuracy: 0.8021\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.5789 - accuracy: 0.3415 - partial_correct_accuracy: 0.5738 - val_loss: 0.4120 - val_accuracy: 0.3542 - val_partial_correct_accuracy: 0.8813\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4791 - accuracy: 0.3728 - partial_correct_accuracy: 0.6462 - val_loss: 0.4122 - val_accuracy: 0.3438 - val_partial_correct_accuracy: 0.8146\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.3733 - accuracy: 0.3879 - partial_correct_accuracy: 0.7211 - val_loss: 0.4654 - val_accuracy: 0.4688 - val_partial_correct_accuracy: 0.7729\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2782 - accuracy: 0.4274 - partial_correct_accuracy: 0.7963 - val_loss: 0.5008 - val_accuracy: 0.1562 - val_partial_correct_accuracy: 0.8000\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2120 - accuracy: 0.4355 - partial_correct_accuracy: 0.8393 - val_loss: 0.4682 - val_accuracy: 0.2500 - val_partial_correct_accuracy: 0.8042\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.1555 - accuracy: 0.4541 - partial_correct_accuracy: 0.8783 - val_loss: 0.6392 - val_accuracy: 0.5521 - val_partial_correct_accuracy: 0.7625\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.1298 - accuracy: 0.4228 - partial_correct_accuracy: 0.9070 - val_loss: 0.7449 - val_accuracy: 0.2396 - val_partial_correct_accuracy: 0.7583\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.0974 - accuracy: 0.4762 - partial_correct_accuracy: 0.9234 - val_loss: 0.7523 - val_accuracy: 0.4271 - val_partial_correct_accuracy: 0.7625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def partial_correct_accuracy(\n",
        "    y_true,\n",
        "    y_pred,\n",
        ") -> float:\n",
        "\n",
        "    count = 0\n",
        "\n",
        "    for i in range(len(y_true)):\n",
        "        p = sum(np.logical_and(y_true[i], y_pred[i]))\n",
        "        q = sum(np.logical_or(y_true[i], y_pred[i]))\n",
        "\n",
        "        count += p / q\n",
        "\n",
        "    return count / len(y_true)\n",
        "y_pred = model.predict(testX)\n",
        "y_pred = np.where(y_pred >= 0.5, 1, 0)\n",
        "print(\"accuracy: \", partial_correct_accuracy(testY, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtxQK_ZyNFNc",
        "outputId": "22e8cb7c-2abc-4c76-b136-2613c3305255"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 8ms/step\n",
            "accuracy:  0.5609375000000001\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "V9XxJrdrfQbI"
      ],
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}